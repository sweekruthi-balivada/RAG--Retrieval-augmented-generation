{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Part B: Write a chatbot prompt to iteratively create a sequence of chats on one particular custom data.\n",
        "\n",
        "1. The chatbot should be able to answer the questions based on the text data or multiple documents.\n",
        "\n",
        "2. The chatbot should save the conversation in the memory.\n",
        "\n",
        "2. Summarize the chats at the end of the conversation."
      ],
      "metadata": {
        "id": "DrOzgnx9pF86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip -q install langchain\n",
        "!pip -q install openai\n",
        "!pip -q install tiktoken\n",
        "!pip -q install faiss-gpu\n",
        "!pip -q install langchain_experimental\n",
        "!pip -q install \"langchain[docarray]\"\n",
        "!pip -q install openai\n",
        "!pip -q install PyPDF2\n",
        "!pip -q install templates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r9tpzmJjiGe",
        "outputId": "3c04c64b-254a-44b6-dd52-a604c8b463c1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/73.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "yVBwuSjefi0H"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n"
      ],
      "metadata": {
        "id": "r9FedYLqeayO"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loading"
      ],
      "metadata": {
        "id": "oH6lokjQtVa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text_from_pdf(pdf_files):\n",
        "    text = \"\"\n",
        "    for pdf in pdf_files:\n",
        "        file = PdfReader(pdf)\n",
        "        for page in file.pages:\n",
        "            text += page.extract_text()\n",
        "    return text"
      ],
      "metadata": {
        "id": "K2M1aezktO8Y"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chunking"
      ],
      "metadata": {
        "id": "5fUPs2sdtZuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(raw_text):\n",
        "    text = CharacterTextSplitter(\n",
        "        separator=\"\\n\",\n",
        "        chunk_size=900,\n",
        "        chunk_overlap=300,\n",
        "        length_function=len\n",
        "    )\n",
        "    chunks = text.split_text(raw_text)\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "cPTIJg0FtF9-"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding"
      ],
      "metadata": {
        "id": "KsO1WBHRtb14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vectorstore(chunks):\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    vectorstore = FAISS.from_texts(texts=chunks, embedding=embeddings)\n",
        "    return vectorstore"
      ],
      "metadata": {
        "id": "PpluAr9FtBuI"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "WmYS9VF1tdjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_convo_chain(vectorstore):\n",
        "\n",
        "    llm = ChatOpenAI()\n",
        "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "    convo_chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm = llm,\n",
        "        retriever = vectorstore.as_retriever(),\n",
        "        memory = memory\n",
        "    )\n",
        "    return convo_chain"
      ],
      "metadata": {
        "id": "36GZmbxPsm7o"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "2IXFFQyttiQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_user_input(user_query, conver_chain):\n",
        "    response = conver_chain({'question': user_query})\n",
        "    chat_history = response['chat_history']\n",
        "    return chat_history[-1].content"
      ],
      "metadata": {
        "id": "diAbhnfwsVQO"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chatbot"
      ],
      "metadata": {
        "id": "7hqbcyJ7tjvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    load_dotenv()\n",
        "\n",
        "    docs = []  # List to hold PDF file paths\n",
        "    pdf_files = os.listdir(\"/content/drive/MyDrive/pdf_folder_chatbot\")  # Directory containing PDF files\n",
        "\n",
        "    # Read PDF files and extract text\n",
        "    for file in pdf_files:\n",
        "        if file.endswith(\".pdf\"):\n",
        "            docs.append(os.path.join(\"/content/drive/MyDrive/pdf_folder_chatbot\", file))\n",
        "    pdf_content = get_text_from_pdf(docs)\n",
        "\n",
        "    # Chunk text\n",
        "    chunks = chunk_text(pdf_content)\n",
        "\n",
        "    # Get vectorstore\n",
        "    vectorstore = get_vectorstore(chunks)\n",
        "\n",
        "    # Get conversation chain\n",
        "    convo_chain = get_convo_chain(vectorstore)\n",
        "\n",
        "    print(\"Ask any query regarding your data or enter 'quit' to exit\")\n",
        "\n",
        "    while True:\n",
        "        user_query = input(\"You: \")\n",
        "        if user_query.lower() == \"quit\":\n",
        "            break\n",
        "        response = chat_user_input(user_query, convo_chain)\n",
        "        print(\"ChatBot:\", response)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb5010OYkRlR",
        "outputId": "fc6ef28c-7767-461d-da77-34c68b0b43c6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ask any query regarding your data or enter 'quit' to exit\n",
            "You: what is the pdf about?\n",
            "ChatBot: The PDF is about a keynote talk on a Smart City Traffic Drone AI Cloud Platform presented by Jerry Gao. It discusses the use of intelligence, big data, and AI cloud infrastructure in managing city traffic, including real-time traffic information, monitoring, analysis, congestion detection, collision detection, emergency response, and more. It also covers the use of machine learning models for satellite image-based road segmentation, vehicle detection, and counting in the context of smart city traffic management.\n",
            "You: what are the key concepts in the pdf?\n",
            "ChatBot: The key concepts discussed in the PDF about the keynote talk on a Smart City Traffic Drone AI Cloud Platform presented by Jerry Gao include:\n",
            "\n",
            "1. Smart City Traffic Intelligence Cloud Stack\n",
            "2. Private Traffic Cloud, Public Traffic Cloud, and Hybrid Traffic Cloud\n",
            "3. Real-time city traffic monitoring and flow analysis\n",
            "4. Intelligent traffic congestion detection and analysis\n",
            "5. Smart traffic collision detection and classification\n",
            "6. Real-time intelligent traffic emergency response\n",
            "7. Reduction of city traffic infrastructure maintenance costs\n",
            "8. Seamless smart city traffic cloud platform deployment and upgrades\n",
            "9. Real-time smart city traffic reports to city agents, traffic emergency teams, media, and the public.\n",
            "\n",
            "Additionally, the talk covers advanced technology concepts such as edge computing, IoT, UAV, AI, big data, smart traffic decision intelligence, and simulation in the context of managing city traffic efficiently.\n",
            "You: How is it helpful to the society\n",
            "ChatBot: The keynote talk on a Smart City Traffic Drone AI Cloud Platform presented by Jerry Gao contributes to society by offering solutions to improve city traffic control and management. It provides real-time city traffic information, intelligent traffic congestion detection, collision detection, emergency response, and decision-making support. By utilizing advanced technologies like AI, big data, and cloud computing, the platform aims to enhance traffic flow, reduce maintenance costs, and provide valuable insights to city agencies, emergency teams, media, and the public. Ultimately, the implementation of such a system can lead to more efficient traffic management, improved safety, and a better overall quality of life in urban areas.\n",
            "You: Summarize our chat for today!\n",
            "ChatBot: Today, we discussed the work and expertise of Jerry Gao, a Professor at San Jose State University, who is involved in research on Smart Complex Systems and is the Founder and CEO of 3iCloud.co. Specifically, we delved into the focus on enhancing city traffic control systems through real-time monitoring, intelligent congestion detection, collision analysis, and emergency response using advanced technologies like drones, AI, and big data. The goal is to provide a comprehensive 3D city traffic system infrastructure that supports continuous monitoring, analysis, and decision-making for efficient traffic management in smart cities.\n",
            "You: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aYelu0r5tw8J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}